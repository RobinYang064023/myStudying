# Spark Purpose
---

Spark aims at speed, ease of use, extensibility and interactive analytics when doing iterative or interactive data mining with cluster computing.


# Why Spark can do this?
---

Spark provides an efficient abstraction for in-memory cluster computing called Resiilient Distributed Dataset(RDD).

# What Programming Languages are supported by Spark
---
Spark is mainly written in Scala, but provides developer API for languages like JAVA, Python, and R.

_Note_: There are some third-party projects aim to provide developer API for Additional Language Bindings,such as below:

- C# / .NET
    - Mobius: C# and F# language binding and extensions to Apache Spark
- Clojure
    - clj-spark
- Groovy
    - groovy-spark-example
- Julia
    - Spark.jl

# Supported Data Format
---

1. Parquet
2. Avro
3. CSV
4. JSON


# 
