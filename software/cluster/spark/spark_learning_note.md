## Spark Purpose

---

Spark aims at speed, ease of use, extensibility and interactive analytics when doing iterative or interactive data mining with cluster computing.

## Why Spark can do this?

---

Spark provides an efficient abstraction for in-memory cluster computing called Resiilient Distributed Dataset(RDD).

## What Programming Languages are supported by Spark

---
Spark is mainly written in Scala, but provides developer API for languages like JAVA, Python, and R.

_Note_: There are some third-party projects aim to provide developer API for Additional Language Bindings,such as below:

- C# / .NET
  - Mobius: C# and F# language binding and extensions to Apache Spark
- Clojure
  - clj-spark
- Groovy
  - groovy-spark-example
- Julia
  - Spark.jl

## Supported Data Format

---

1. Parquet
2. Avro
3. CSV
4. JSON
